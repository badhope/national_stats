"""
å‘½ä»¤è¡Œå·¥å…·æ¨¡å¼
æ”¯æŒæ— ç•Œé¢è¿è¡Œã€è‡ªåŠ¨åŒ–ä»»åŠ¡ã€æ‰¹é‡å¯¼å‡º
"""

import argparse
import sys
from pathlib import Path
import json
import pandas as pd
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from core.scraper import NationalBureauScraper
from core.predictor import ComprehensivePredictor
from core.reporter import ReportGenerator
from config import METRICS, EXPORT_DIR


def run_cli():
    parser = argparse.ArgumentParser(
        description='å›½å®¶ç»Ÿè®¡å±€æ•°æ®åˆ†æç³»ç»Ÿ CLI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å–GDPæ•°æ®å¹¶å¯¼å‡ºCSV
  python cli.py fetch --metric gdp --start 2015 --end 2023 --export csv
  
  # è·å–æ‰€æœ‰æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š
  python cli.py analyze --all --start 2010 --end 2024 --report
  
  # é¢„æµ‹æœªæ¥5å¹´GDP
  python cli.py predict --metric gdp --years 5
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # fetch å‘½ä»¤
    fetch_parser = subparsers.add_parser('fetch', help='è·å–æ•°æ®')
    fetch_parser.add_argument('--metric', type=str, choices=list(METRICS.keys()) + ['all'], 
                             default='all', help='æ•°æ®æŒ‡æ ‡ç±»å‹')
    fetch_parser.add_argument('--start', type=int, default=2010, help='èµ·å§‹å¹´ä»½')
    fetch_parser.add_argument('--end', type=int, default=2024, help='ç»“æŸå¹´ä»½')
    fetch_parser.add_argument('--export', type=str, choices=['csv', 'json', 'excel'], 
                             help='å¯¼å‡ºæ ¼å¼')
    
    # analyze å‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='æ•°æ®åˆ†æ')
    analyze_parser.add_argument('--all', action='store_true', help='åˆ†ææ‰€æœ‰æ•°æ®')
    analyze_parser.add_argument('--start', type=int, default=2010)
    analyze_parser.add_argument('--end', type=int, default=2024)
    analyze_parser.add_argument('--report', action='store_true', help='ç”ŸæˆæŠ¥å‘Š')
    
    # predict å‘½ä»¤
    predict_parser = subparsers.add_parser('predict', help='è¶‹åŠ¿é¢„æµ‹')
    predict_parser.add_argument('--metric', type=str, required=True)
    predict_parser.add_argument('--years', type=int, default=5, help='é¢„æµ‹æœªæ¥å¹´æ•°')
    
    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        return
    
    scraper = NationalBureauScraper()
    predictor = ComprehensivePredictor()
    reporter = ReportGenerator(EXPORT_DIR)
    
    if args.command == 'fetch':
        print(f"ğŸ“Š æ­£åœ¨è·å–æ•°æ®: {args.metric} ({args.start}-{args.end})")
        
        if args.metric == 'all':
            data = scraper.fetch_all_parallel(args.start, args.end)
        else:
            df = scraper.fetch_data(args.metric, args.start, args.end)
            data = {args.metric: df}
        
        # æ‰“å°é¢„è§ˆ
        for key, df in data.items():
            print(f"\n{'='*50}")
            print(f" {METRICS[key]['name']}")
            print('='*50)
            print(df.head().to_string())
        
        # å¯¼å‡º
        if args.export:
            for key, df in data.items():
                if args.export == 'csv':
                    path = EXPORT_DIR / f"{key}_{args.start}_{args.end}.csv"
                    df.to_csv(path, index=False)
                elif args.export == 'json':
                    path = EXPORT_DIR / f"{key}_{args.start}_{args.end}.json"
                    df.to_json(path, orient='records', force_ascii=False)
                elif args.export == 'excel':
                    path = EXPORT_DIR / f"{key}_{args.start}_{args.end}.xlsx"
                    df.to_excel(path, index=False)
                print(f"\nâœ… å·²å¯¼å‡º: {path}")
    
    elif args.command == 'analyze':
        print("ğŸ“ˆ æ­£åœ¨è¿›è¡Œç»¼åˆåˆ†æ...")
        
        data = scraper.fetch_all_parallel(args.start, args.end)
        predictions = predictor.predict_all_metrics(data)
        
        # æ§åˆ¶å°è¾“å‡ºåˆ†æç»“æœ
        for key, pred in predictions.items():
            print(f"\n{key.upper()} é¢„æµ‹ç»“æœ:")
            if 'best_model' in pred:
                print(f"  æœ€ä½³æ¨¡å‹: {pred['best_model']}")
                print(f"  RÂ²å¾—åˆ†: {pred['best_result']['metrics']['r2']:.4f}")
        
        if args.report:
            md_path = reporter.generate_markdown_report(data, {}, predictions)
            print(f"\nğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {md_path}")
    
    elif args.command == 'predict':
        print(f"ğŸ”® æ­£åœ¨é¢„æµ‹: {args.metric} æœªæ¥ {args.years} å¹´")
        
        # è·å–å†å²æ•°æ®
        df = scraper.fetch_data(args.metric, 2010, 2024)
        
        # è¿›è¡Œé¢„æµ‹
        predictions = predictor.predict_all_metrics({args.metric: df}, args.years)
        
        if args.metric in predictions:
            pred = predictions[args.metric]
            print(f"\né¢„æµ‹ç»“æœ:")
            for x, y in zip(pred['best_result']['x'], pred['best_result']['y']):
                print(f"  {int(x)}: {y:,.2f}")


if __name__ == "__main__":
    run_cli()
